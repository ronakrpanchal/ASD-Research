{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855ddf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os, json\n",
    "\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9688b157",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/kaggle/input/autism-image-data/AutismDataset\"\n",
    "MODEL_PATH = \"/kaggle/input/autism-spectrum-detection-from-kaggle-zenodo/Model results/Model results/best_densenet201_autism.pth\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "OUTPUT_PATH = \"/kaggle/working\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae3162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_dataset():\n",
    "    \"\"\"Load and summarize test dataset structure and return metadata.\n",
    "    Preview samples randomly drawn (up to 5 per class).\"\"\"\n",
    "    test_path = os.path.join(DATA_PATH, \"test\")\n",
    "\n",
    "    if not os.path.exists(test_path):\n",
    "        print(f\"Test directory not found: {test_path}\")\n",
    "        return None\n",
    "\n",
    "    # Get all image files\n",
    "    image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']\n",
    "    all_images = []\n",
    "\n",
    "    for ext in image_extensions:\n",
    "        all_images.extend(glob.glob(os.path.join(test_path, ext)))\n",
    "        all_images.extend(glob.glob(os.path.join(test_path, ext.upper())))\n",
    "\n",
    "    autistic_images = [img for img in all_images if 'Autistic.' in os.path.basename(img)]\n",
    "    non_autistic_images = [img for img in all_images if 'Non_Autistic.' in os.path.basename(img)]\n",
    "\n",
    "    print(\"Test Dataset Summary:\")\n",
    "    print(f\"  Total images: {len(all_images)}\")\n",
    "    print(f\"  Autistic images: {len(autistic_images)}\")\n",
    "    print(f\"  Non-Autistic images: {len(non_autistic_images)}\")\n",
    "\n",
    "    import random\n",
    "    sample_autistic = random.sample(autistic_images, min(5, len(autistic_images))) if autistic_images else []\n",
    "    sample_non_autistic = random.sample(non_autistic_images, min(5, len(non_autistic_images))) if non_autistic_images else []\n",
    "\n",
    "    return {\n",
    "        'all_images': all_images,\n",
    "        'autistic_images': autistic_images,\n",
    "        'non_autistic_images': non_autistic_images,\n",
    "        'sample_autistic': sample_autistic,\n",
    "        'sample_non_autistic': sample_non_autistic\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480d611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial dataset loading (selection occurs AFTER predictions)\n",
    "import random\n",
    "\n",
    "test_dataset = load_test_dataset()\n",
    "\n",
    "selected_image_paths = []  # will be populated after predictions\n",
    "\n",
    "if not test_dataset:\n",
    "    print(\"No dataset information available. Please check the data path.\")\n",
    "else:\n",
    "    print(\"Dataset loaded. Run model + prediction cells to generate selection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c165a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize and take the center part of image to what our model expects\n",
    "def get_input_transform():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet normalization\n",
    "    ])   \n",
    "\n",
    "    return transform\n",
    "\n",
    "def get_input_tensors(img):\n",
    "    transform = get_input_transform()\n",
    "    # unsqueeze converts single image to batch of 1\n",
    "    return transform(img).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e442de5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_densenet201_model(num_classes=2, pretrained=True, dropout_rate=0.5):\n",
    "    \"\"\"\n",
    "    Create DenseNet201 model with custom classification head\n",
    "    \n",
    "    Args:\n",
    "        num_classes (int): Number of output classes\n",
    "        pretrained (bool): Whether to use pretrained weights\n",
    "        dropout_rate (float): Dropout rate for regularization\n",
    "    \"\"\"\n",
    "    # Load pretrained DenseNet201\n",
    "    model = models.densenet201(pretrained=pretrained)\n",
    "    \n",
    "    # Get the number of features from the classifier\n",
    "    num_features = model.classifier.in_features\n",
    "    \n",
    "    # Replace the classifier with our custom head\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(dropout_rate),\n",
    "        nn.Linear(num_features, 512),\n",
    "        nn.BatchNorm1d(512),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(dropout_rate/2),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.BatchNorm1d(256),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(dropout_rate/4),\n",
    "        nn.Linear(256, num_classes)\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bd0202",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_densenet201_model(num_classes=2)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.to(DEVICE)\n",
    "print(\"model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5f03e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_samples_by_prediction(results, total=6, ratio_correct=0.5, shuffle=True, seed=None):\n",
    "    \"\"\"Select image records based on model prediction correctness balance.\"\"\"\n",
    "    if not results:\n",
    "        return [], []\n",
    "    import random\n",
    "    rnd = random.Random(seed)\n",
    "    correct = [r for r in results if r['correct']]\n",
    "    incorrect = [r for r in results if not r['correct']]\n",
    "    if shuffle:\n",
    "        rnd.shuffle(correct)\n",
    "        rnd.shuffle(incorrect)\n",
    "    need_correct = int(round(total * ratio_correct))\n",
    "    need_incorrect = total - need_correct\n",
    "    sel_correct = correct[:need_correct]\n",
    "    sel_incorrect = incorrect[:need_incorrect]\n",
    "    if len(sel_correct) < need_correct:\n",
    "        deficit = need_correct - len(sel_correct)\n",
    "        extras = incorrect[need_incorrect:need_incorrect+deficit]\n",
    "        sel_incorrect.extend(extras)\n",
    "    if len(sel_incorrect) < need_incorrect:\n",
    "        deficit = need_incorrect - len(sel_incorrect)\n",
    "        extras = correct[need_correct:need_correct+deficit]\n",
    "        sel_correct.extend(extras)\n",
    "    selected = sel_correct + sel_incorrect\n",
    "    if shuffle:\n",
    "        rnd.shuffle(selected)\n",
    "    return selected, [r['path'] for r in selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cbca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: compute predictions over all test images\n",
    "from typing import List, Dict\n",
    "\n",
    "def compute_predictions(test_dataset, batch_size=16):\n",
    "    if not test_dataset:\n",
    "        print(\"No dataset info provided.\")\n",
    "        return []\n",
    "    image_paths = test_dataset['all_images']\n",
    "    results = []\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    softmax = torch.nn.Softmax(dim=1)\n",
    "    model.eval()\n",
    "\n",
    "    def true_label_from_name(p):\n",
    "        name = os.path.basename(p)\n",
    "        if 'Non_Autistic.' in name:\n",
    "            return 0\n",
    "        if 'Autistic.' in name:\n",
    "            return 1\n",
    "        return None\n",
    "\n",
    "    batch = []\n",
    "    batch_meta = []\n",
    "\n",
    "    def flush_batch():\n",
    "        if not batch:\n",
    "            return\n",
    "        with torch.no_grad():\n",
    "            tensor_batch = torch.stack(batch).to(DEVICE)\n",
    "            logits = model(tensor_batch)\n",
    "            probs = softmax(logits)\n",
    "            confs, preds = torch.max(probs, 1)\n",
    "            for meta, pred, conf, prob_vec in zip(batch_meta, preds.cpu(), confs.cpu(), probs.cpu()):\n",
    "                results.append({\n",
    "                    'path': meta['path'],\n",
    "                    'true': meta['true'],\n",
    "                    'pred': int(pred.item()),\n",
    "                    'conf': float(conf.item()),\n",
    "                    'prob_autistic': float(prob_vec[1].item()),\n",
    "                    'correct': (meta['true'] is not None and int(pred.item()) == meta['true'])\n",
    "                })\n",
    "        batch.clear()\n",
    "        batch_meta.clear()\n",
    "\n",
    "    for p in image_paths:\n",
    "        tlabel = true_label_from_name(p)\n",
    "        try:\n",
    "            img = Image.open(p).convert('RGB')\n",
    "            batch.append(transform(img))\n",
    "            batch_meta.append({'path': p, 'true': tlabel})\n",
    "            if len(batch) == batch_size:\n",
    "                flush_batch()\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {p}: {e}\")\n",
    "    flush_batch()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74390fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If your dataset labels were 0 = non-autistic, 1 = autistic\n",
    "idx2label = [\"non-autistic\", \"autistic\"]\n",
    "cls2idx = {\"non-autistic\": 1, \"autistic\": 0}\n",
    "cls2label = {\"non-autistic\": \"non-autistic\", \"autistic\": \"autistic\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497aa831",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # put model in eval mode\n",
    "\n",
    "for img in selected_image_paths:\n",
    "    img_t = get_input_tensors(Image.open(img)).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        output = model(img_t)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    predicted_label = idx2label[predicted.item()]\n",
    "    print(f\"Image: {os.path.basename(img)} | Predicted: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c57a64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predictions and select sample set\n",
    "prediction_records = compute_predictions(test_dataset)\n",
    "print(f\"Computed predictions for {len(prediction_records)} images\")\n",
    "\n",
    "sample_records, selected_image_paths = select_samples_by_prediction(\n",
    "    prediction_records,\n",
    "    total=6,\n",
    "    ratio_correct=0.8,\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    ")\n",
    "\n",
    "print(\"Selected sample set (filename | prob_autistic | correct):\")\n",
    "for r in sample_records:\n",
    "    status = 'OK' if r['correct'] else 'WRONG'\n",
    "    print(f\"  {os.path.basename(r['path'])} | {r['prob_autistic']:.3f} | {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97939f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize selected samples with prediction status\n",
    "if selected_image_paths:\n",
    "    cols = min(3, len(selected_image_paths))\n",
    "    rows = (len(selected_image_paths) + cols - 1) // cols\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 4 * rows))\n",
    "    if rows == 1:\n",
    "        axes = np.array([axes])\n",
    "    axes = axes.flatten()\n",
    "    meta_by_path = {r['path']: r for r in sample_records}\n",
    "    for i, p in enumerate(selected_image_paths):\n",
    "        img = Image.open(p)\n",
    "        axes[i].imshow(img)\n",
    "        rec = meta_by_path.get(p, {})\n",
    "        status = 'OK' if rec.get('correct') else 'WRONG'\n",
    "        prob = rec.get('prob_autistic')\n",
    "        prob_txt = f\"p_aut={prob:.2f}\" if prob is not None else ''\n",
    "        axes[i].set_title(f\"{os.path.basename(p)}\\n{status} {prob_txt}\", fontsize=10)\n",
    "        axes[i].axis('off')\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "    plt.suptitle('Selected Samples (Post-Prediction)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No selected images to visualize yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b88f4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87edb78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
